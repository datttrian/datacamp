{"cells":[{"cell_type":"markdown","id":"a6d014ee-e3b7-409c-948b-ac0152f49563","metadata":{},"source":["# Prompt Engineering with GPT and LangChain"]},{"cell_type":"markdown","id":"9a610d9c-089e-4b41-803d-17024f68c51a","metadata":{},"source":["LangChain is framework that is extremely helpful for prompt engineering and the integration of generative AI capabilities in applications or data platforms. It has many capabilities, some of which will not be introduced until later modules, but we will start with a gentle introduction to some of the easy-to-understand concepts in the framework.\n","\n","You'll build an AI agent that uses Python and GPT to perform sentiment analysis on financial headlines.\n","\n","In more detail, you'll cover:\n","- Getting set up with an OpenAI developer account and integration with Workspace.\n","- Interacting with OpenAI models through the langchain framework.\n","- Using prompt templates that write reusable, dynamic prompts.\n","- Working with LLM chains.\n","- Automatically parsing the output of an LLM to be used downstream.\n","- Working with langchain agents and tools.\n","- Using the OpenAI Moderation API to filter explicit content.\n","\n","For this project, we are using two small samples: `financial_headlines.txt` and `reddit_comments.txt`. These 5-6 line samples are kept short to keep evaluation easy, but keep in mind that this same code and prompt engineering techniques can scale to datasets of much larger size."]},{"cell_type":"markdown","id":"9358e4e8-7bba-4f77-a4c1-80a49c57869e","metadata":{},"source":["### Before you begin"]},{"cell_type":"markdown","id":"51a7c002-1011-401e-b7f1-c8f92cee40a8","metadata":{},"source":["You'll need a developer account with OpenAI.\n","\n","See getting-started.ipynb for steps on how to create an API key and store it in Workspace. In particular, you'll need to follow the instructions in the \"Getting started with OpenAI\" and \"Setting up Workspace Integrations\" sections."]},{"cell_type":"markdown","id":"833b24bb-221d-4d34-9927-8b83496fb65d","metadata":{},"source":["## Task 0: Setup"]},{"cell_type":"markdown","id":"2c4850c8-97f7-4389-96c6-9f44ecbfd06d","metadata":{},"source":["We need to install a few packages, one of which being the `langchain` package. This is currently being developed quickly, sometimes with breaking changes, so we fix the version.\n","\n","`langchain` depends on a recent version of `typing_extensions`, so we need to update that package, again fixing the version."]},{"cell_type":"markdown","id":"115b1f8e-55a2-471e-8c45-0eaf3e685a44","metadata":{},"source":["### Instructions\n","\n","Run the following code to install `openai`, `langchain`, `typing_extensions` and `pandas`."]},{"cell_type":"code","execution_count":1,"id":"4de2a21d-1d16-4bef-b401-64760a2b9735","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai in /workspaces/datacamp/.venv/lib/python3.12/site-packages (1.23.6)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai) (4.3.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai) (2.7.1)\n","Requirement already satisfied: sniffio in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai) (4.8.0)\n","Requirement already satisfied: idna>=2.8 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: certifi in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"]}],"source":["# Install openai.\n","!pip install openai"]},{"cell_type":"code","execution_count":2,"id":"64096b2a-d970-4045-8fd1-883f0bb61b4b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain in /workspaces/datacamp/.venv/lib/python3.12/site-packages (0.1.16)\n","Requirement already satisfied: PyYAML>=5.3 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (2.0.29)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (0.0.34)\n","Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (0.1.46)\n","Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (0.0.1)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (0.1.51)\n","Requirement already satisfied: numpy<2,>=1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (2.7.1)\n","Requirement already satisfied: requests<3,>=2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"]}],"source":["# Install langchain.\n","!pip install langchain"]},{"cell_type":"code","execution_count":3,"id":"93009418-4306-4645-ae65-184741201267","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: typing-extensions==4.8.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (4.8.0)\n"]}],"source":["# Install typing-extensions.\n","!pip install typing-extensions==4.8.0"]},{"cell_type":"code","execution_count":4,"id":"b00a5793-03ab-4176-9843-eeaaf224dbb7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in /workspaces/datacamp/.venv/lib/python3.12/site-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.26.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}],"source":["# Install pandas.\n","!pip install pandas"]},{"cell_type":"markdown","id":"be271ab6-b977-45b3-8b5d-f86b73e9fd2b","metadata":{},"source":["For this project, we need first need to load the openai and os packages to set the API key from the environment variables you just created."]},{"cell_type":"markdown","id":"30c2c737-4fd2-4a6a-b9c0-710118699d86","metadata":{},"source":["### Instructions\n","\n","- Import the `os` package.\n","- Import the `openai` package.\n","- Set `openai.api_key` to the `OPENAI_API_KEY` environment variable."]},{"cell_type":"code","execution_count":5,"id":"8933db02","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-dotenv in /workspaces/datacamp/.venv/lib/python3.12/site-packages (1.0.1)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install python-dotenv"]},{"cell_type":"code","execution_count":6,"id":"a519d4a9","metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from dotenv import load_dotenv\n","\n","# Load environment variables from .env file\n","load_dotenv()\n"]},{"cell_type":"code","execution_count":7,"id":"2d301524-67c0-4894-8e2a-72787de3c9bc","metadata":{},"outputs":[],"source":["# Import the os package.\n","import os\n","\n","# Import the openai package.\n","import openai\n","\n","# Set openai.api_key to the OPENAI_API_KEY environment variable.\n","openai.api_key = os.environ[\"OPENAI_API_KEY\"]"]},{"cell_type":"markdown","id":"8fa361c0-da75-42f5-84c7-142ed2307c20","metadata":{},"source":["For the `langchain` package, let's start by importing it's `OpenAI` and `ChatOpenAI` class, which are used to interact with completion models and chat completion models respectively.\n","\n","Completion models, such as the GPT-1, GPT-2, GPT-3 and GPT-3.5, work as an advanced autocomplete model. Given a certain snippet of text as input, they will complete the text until a certain point. This could be either an end-of-sequence token (a natural way of stopping), the model reaching its maximum token limit for outputs and so on.\n","\n","Chat completion models, such as GPT-3.5-Turbo (the ChatGPT model) and GPT-4, are designed for conversational use. These models are typically more fine-tuned for conversations, keep a prompt/conversation history and allow access to a system message, which we can use as a meta prompt to define a role, a tone of voice, a scope, etc.\n","\n","Completion models and chat completion models tend to work with different classes and functions in the SDK. For that reason, we will start by importing both classes."]},{"cell_type":"markdown","id":"f18c0e9a-dcc2-4862-895b-e6ecb4347e5f","metadata":{},"source":["### Instructions\n","\n","- Import `OpenAI` from `langchain.llms`.\n","- Import `ChatOpenAI` from `langchain.chat_models`."]},{"cell_type":"markdown","id":"b0e7d533-4a77-4c17-a9c2-22b4a76b458f","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","    \n","Remember the syntax for Python imports: `from ... import ...`\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":8,"id":"e08d7737-e753-4e54-9ae4-b65e365bf36f","metadata":{},"outputs":[],"source":["# Import OpenAI.\n","from langchain.llms import OpenAI\n","\n","# Import ChatOpenAI.\n","from langchain.chat_models import ChatOpenAI"]},{"cell_type":"markdown","id":"303fc31e-5f83-41a3-a078-e929a11e8bf0","metadata":{},"source":["## Task 1: Import the Financial News Headlines Data"]},{"cell_type":"markdown","id":"b1c1b04e-0de7-4050-950e-4f64dfc6a58d","metadata":{},"source":["A small sample of financial headlines is stored in `financial_headlines.txt`.\n","\n","Our first step is to read in the text file and store the headlines in a Python list."]},{"cell_type":"markdown","id":"10678d41-3b1c-4471-9e4c-9b1f32ea038f","metadata":{},"source":["### Instructions\n","\n","Import the text file to a Python list.\n","\n","- Open `financial_headlines.txt` for reading.\n","- Read in the lines using the `.readlines()` method. Assign to `headlines`.\n","- Print the sample headlines."]},{"cell_type":"markdown","id":"6afdccc3-7743-4a14-9d98-8aa3b32166be","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","- A good way of opening (and automatically closing) a file is using: `with open(file_name, \"r\") as file:`.\n","- We can then use the `.readlines()` method on the `file` variable.\n","    \n","</p>\n","</details>"]},{"cell_type":"code","execution_count":9,"id":"1b5638c5-9db0-4731-8170-e7b6c1a99697","metadata":{},"outputs":[{"data":{"text/plain":["[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\\n\",\n"," 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\n',\n"," 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\n',\n"," 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\n',\n"," \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\\n\",\n"," 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Open the text file and read its lines.\n","with open('financial_headlines.txt', 'r') as data:\n","    headlines = data.readlines()\n","\n","# Print all headlines.\n","headlines"]},{"cell_type":"markdown","id":"7c0a4789-58a1-4546-bb39-c5b540eb8559","metadata":{},"source":["The headlines seem to a bit of whitespace preceding the punctuation, but this does not influence the performance of our large language model.\n","You can also see that every headline ends with a new line (`\\n`).\n","\n","We can quickly strip the `\\n` from the end of each headline, as this might improve visibility later down the line, when printing these headlines in a dataframe. "]},{"cell_type":"markdown","id":"5c7b522e-32b6-4818-9834-f0c2bbf7f230","metadata":{},"source":["### Instructions\n","\n","Strip the `\\n` character from the end of every news headline.\n","\n","- Loop through `headlines` and use the `.strip()` method to remove the `\\n` character from each line.\n","- Print the result."]},{"cell_type":"markdown","id":"06c8394a-0d77-4d68-a20a-06c1701a8370","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","To quickly reassign the adjusted elements of our list, we can make use of Python list comprehensions.\n","    \n","For example: `new_list = [f(x) for x in list]`\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":10,"id":"980f8d06-4d48-4fb9-9cab-ac66a8371910","metadata":{},"outputs":[{"data":{"text/plain":["[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\",\n"," 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .',\n"," 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .',\n"," 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .',\n"," \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\",\n"," 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Strip the new line character from all headlines.\n","headlines = [line.strip(\"\\n\") for line in headlines]\n","\n","# Print all headlines.\n","headlines"]},{"cell_type":"markdown","id":"f389f489-eddd-45c0-84d7-44dd8f9ca5b3","metadata":{},"source":["## Task 2: Setting up Prompt Templates"]},{"cell_type":"markdown","id":"f9f0adf8-630d-4738-95a2-9a8abc0edd67","metadata":{},"source":["During this code-along we are using the OpenAI API to programmatically make requests to a GPT-model. This allows us to automate calls to the model, as would be the case when implementing generative AI functionalities in an application or data transformation process.\n","\n","In general, when developing an application, we want our code to be modular, scalable and reusable. How do we this with LLM prompts?\n","\n","This is where Prompt Templates come into play! It allows for dynamic prompts, with built-in verification tools on whether all inputs are given (this will ease the load on testing). They can easily be saved, versioned and integrated into the code base of an application.\n","\n","We will set up Prompt Templates (from the `langchain` package) to automatically determine financial sentiment from the headlines and extract relevant company names. "]},{"cell_type":"markdown","id":"ddb5a5e6-e828-4af4-afb4-767dd2ab798b","metadata":{},"source":["### Usage of Prompt Templates\n","\n","A prompt template can have dynamic input, which can be added using `{ }`.\n","\n","Example: `\"Can you give me some suggestions for my trip to {city}?\"`\n","\n","We can then format the prompt template by filling in the `city` variable.\n","\n","Certain prompts that are often reused programmatically in application processes might be very lengthy and can be carefully designed to meet a specific need. For example, if we want the output of a sentiment analysis by the GPT-model to be limited to either positive, negative or neutral (without anything else in the answer), we need to explicitly tell the model within our prompt. In order to not accidentally forget this in any of the future prompts, it is best practice to design and save a prompt template."]},{"cell_type":"markdown","id":"b52a25d6-0bc4-487b-812e-19895b80ea9c","metadata":{},"source":["### Types of Prompt Templates\n","\n","Prompt Templates in Langchain come in two formats:\n","- PromptTemplate: this is used for completion models.\n","- ChatPromptTemplate: this is used for chat completion models. On top of the normal input prompt, these can hold a system message (meta prompt) and a conversation history.\n","\n","Let's start by creating a PromptTemplate and ChatPromptTemplate."]},{"cell_type":"markdown","id":"82de02d9-6a87-4ea1-9b56-c3f03b463748","metadata":{},"source":["### Instructions\n","\n","Create a Prompt Template to analyze financial sentiment.\n","- import `PromptTemplate` from `langchain.prompts`.\n","- Create a `PromptTemplate` object by using its `.from_template()` method. Assign to `prompt_template`.\n","- For the template argument, use:\n","\n","```\n","\"Analyze the following financial headline for sentiment: {headline}\"\n","```\n","\n","- Format the prompt using its `.format()` method. Let's use our first headline as input. Assign to `formatted_prompt`.\n","- Print the formatted prompt."]},{"cell_type":"markdown","id":"f2cde322-6970-43ef-a916-0af0d8bd47be","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","`prompt_template.format()` will have one argument called `headline` (as defined in our `PromptTemplate`), where we pass along the first element of our `headlines` list.\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":11,"id":"e5c74f6d-fad2-4a52-a2e4-653768d33c33","metadata":{},"outputs":[{"data":{"text/plain":["\"Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\""]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Import the PromptTemplate class.\n","from langchain.prompts import PromptTemplate\n","\n","# Create a dynamic template to analyze a single headline.\n","prompt_template = PromptTemplate.from_template(\n","    template=\"Analyze the following financial headline for sentiment: {headline}\",\n",")\n","\n","# Format the prompt template on the first headline of the dataset.\n","formatted_prompt = prompt_template.format(headline=headlines[0])\n","\n","# Print the formatted template.\n","formatted_prompt"]},{"cell_type":"markdown","id":"d858c71f-a8eb-4115-a747-7bd643595ea5","metadata":{},"source":["Now let's set up a `ChatPromptTemplate`, which are compatible with conversational models like GPT-4 and GPT-3.5-Turbo. When using the ChatPromptTemplate, we have the ability to assign a system message, so let's make use of this.\n","\n","In terms of prompt engineering, what we write in the system can heavily influence the quality of the output. Some things we can do using the system message is:\n","- Define a role: *\"You are a X\", \"Your role is to do X\", ...*\n","- Define a tone of voice: *\"Respond in a formal manner\", \"Use customer-oriented language\", ...*\n","- Define restrictions on output format: *\"The format of the output is X\", \"The output is strictly limited to X, Y, Z\", ...*\n","- Define a scope: *\"Only answer questions on topic X\", \"If the user questions is not about X, answer with Y\", ...*\n","\n","You will notice some of these tricks applied to the following system message."]},{"cell_type":"markdown","id":"054ac0a5-48d9-46a8-bc27-412280ea0eee","metadata":{},"source":["### Instructions\n","\n","- Import `ChatPromptTemplate` from `langchain.prompts`.\n","- Define a system message as follows and assign to `system_message`.\n","\n","```\n","\"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \n","This sentiment is to be used to advice financial analysts. \n","The format of the output has to be consistent. \n","The output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n","```\n","\n","- Instantiate a new `ChatPromptTemplate` using its `.from_messages()` method. Assign to `chat_template`.\n","    - This method will take a list of tuples as input. We need two tuples, one for the system message and one for the human message. To distinguish the two, the first element of the tuple is either `\"system\"` or `\"human\"`.\n","    - The second element of the tuple is the actual message, as string. For the system message, you can use the `system_message`variable. For the human message, we can reuse the same message as before (including the input variable `{headlines}`).\n","    \n","- Format the template using its `.format_messages()` method. Let's use our first headline again. Assign to `formatted_chat_template`.\n","- Print the formatted template."]},{"cell_type":"markdown","id":"8636ebd3-e8f2-4b47-b962-bc921e0bced7","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","The input for `ChatPromptTemplate.from_messages()` follows this structure:\n","`[(\"system\", system_message), (\"human\", input_prompt)]`\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":12,"id":"2d621445-3804-442d-8040-8405c6c9c83f","metadata":{},"outputs":[{"data":{"text/plain":["[SystemMessage(content='You are performing sentiment analysis on news headlines regarding financial analysis. \\n    This sentiment is to be used to advice financial analysts. \\n    The format of the output has to be consistent. \\n    The output is strictly limited to any of the following options: [positive, negative, neutral].'),\n"," HumanMessage(content=\"Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\")]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Import the ChatPromptTemplate class.\n","from langchain.prompts import ChatPromptTemplate\n","\n","# Define the system message.\n","system_message = \"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \n","    This sentiment is to be used to advice financial analysts. \n","    The format of the output has to be consistent. \n","    The output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n","\n","# Initialize a new ChatPromptTemplate with a system message and human message.\n","chat_template = ChatPromptTemplate.from_messages([\n","    (\"system\", system_message),\n","    (\"human\", \"Analyze the following financial headline for sentiment: {headline}\"),\n","])\n","\n","# Format the ChatPromptTemplate.\n","formatted_chat_template = chat_template.format_messages(\n","    headline=headlines[0]\n",")\n","\n","# Print the formatted template.\n","formatted_chat_template"]},{"cell_type":"markdown","id":"ec62e063-c2bf-42c9-bb54-f774e3f13ff2","metadata":{},"source":["## Task 3: Setting up LLM Chains"]},{"cell_type":"markdown","id":"907abbe1-0ecb-4b33-8a46-8471c214df38","metadata":{},"source":["We will briefly cover the concept of chains in langchain. LLM Chains are an easy way to combine a model with a prompt template. These chains can be created for both *completion models* and *chat completion models*.\n","\n","LLM Chains can be used to \"chain\" prompt flows, by using the output of a previous chain as input for the next.\n","\n","Let's set up a chain for a completion model first, using the templates that we've just built."]},{"cell_type":"markdown","id":"a597b3fb-9710-4054-a0cc-a0541cfb3f4a","metadata":{},"source":["**Instructions**\n","\n","Create an LLM Chain for a completion model.\n","- Import `LLMChain` from `langchain.chains`.\n","- Instantiate a new `LLMChain`. Assign to `completion_chain`. We need to pass along two parameters for its init function:\n","    - `llm`: Here we can easily pass along a completion model by creating one using `OpenAI()`.\n","    - `prompt`: Here can we use the `prompt_template` we have created before.\n","- Run the chain using its `.run()` method.\n","    - Our prompt template has an input variable called `headline`. This becomes an input parameter for the `.run()` method. Let's pass along the first headline of our dataset here."]},{"cell_type":"code","execution_count":13,"id":"124ea2f9","metadata":{},"outputs":[],"source":["# # Import the LLMChain class.\n","# from langchain.chains import LLMChain\n","\n","# # Create the LLMChain by combining a completion model and a prompt.\n","# completion_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)\n","\n","# # Run the LLMChain.\n","# completion_chain.run(headline=headlines[0])"]},{"cell_type":"code","execution_count":14,"id":"d9de26b5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain-openai in /workspaces/datacamp/.venv/lib/python3.12/site-packages (0.1.4)\n","Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-openai) (0.1.46)\n","Requirement already satisfied: openai<2.0.0,>=1.10.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-openai) (1.23.6)\n","Requirement already satisfied: tiktoken<1,>=0.5.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-openai) (0.6.0)\n","Requirement already satisfied: PyYAML>=5.3 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (6.0.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.1.51)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (23.2)\n","Requirement already satisfied: pydantic<3,>=1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.7.1)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (8.2.3)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.3.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n","Requirement already satisfied: sniffio in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.8.0)\n","Requirement already satisfied: regex>=2022.1.18 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2024.4.16)\n","Requirement already satisfied: requests>=2.26.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n","Requirement already satisfied: idna>=2.8 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.7)\n","Requirement already satisfied: certifi in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai) (3.10.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.18.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.2.1)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -U langchain-openai"]},{"cell_type":"code","execution_count":15,"id":"234126d2-0e6a-4286-8fd9-2ec95eb5a566","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/workspaces/datacamp/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"data":{"text/plain":["'\\n\\nPositive'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Import the LLMChain class.\n","from langchain.chains import LLMChain\n","from langchain_openai import OpenAI\n","\n","# Create the LLMChain by combining a completion model and a prompt.\n","completion_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)\n","\n","# Run the LLMChain.\n","completion_chain.run(headline=headlines[0])"]},{"cell_type":"markdown","id":"20424b97-c01c-4786-9460-beae26fb8a35","metadata":{},"source":["Now let's do the same, using a chat completion model."]},{"cell_type":"markdown","id":"e834ad2f-299b-4834-8e05-56eb0b67e99e","metadata":{},"source":["### Instructions\n","\n","- Instantiate a new `LLMChain`. Assign to `chat_chain`. We need to pass along two parameters for its init function:\n","    - `llm`: Here we can easily pass along a completion model by creating one using `ChatOpenAI()`.\n","    - `prompt`: Here can we use the `chat_template` we have created before.\n","- Run the chain using the `.run()` method of the chain."]},{"cell_type":"markdown","id":"883ddd72-41e3-426b-b969-74129a1a158d","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","`chat_chain.run()` has two input variables, since `chat_template` has two input variables. Make sure to pass along a value for both `headline` and `system_message`.\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":16,"id":"00a8db2b-fd72-421c-9e17-82a47ee460b5","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/workspaces/datacamp/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n","  warn_deprecated(\n"]},{"data":{"text/plain":["'Positive'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Create the LLMChain by combining a chat completion model and a prompt.\n","chat_chain = LLMChain(llm=ChatOpenAI(), prompt=chat_template)\n","\n","# Run the LLMChain.\n","chat_chain.run(headline=headlines[0], system_message=system_message)"]},{"cell_type":"markdown","id":"b55de8b3-7e57-4fcb-b160-462b22828122","metadata":{},"source":["## Task 4: Extracting Company Names with the Output Parser"]},{"cell_type":"markdown","id":"b5c74f27-1a7a-43f8-b0c1-04bfc9611f0f","metadata":{},"source":["Output parsing is a very useful feature in Langchain when integrating LLM outputs into your application. The output parser can automatically transform the output of the GPT-model to numerous data types, such as lists, datetimes, JSONs and so on.\n","\n","In this example, we will ask the GPT-model to extract the company name from every headline and instantly assign them to a Python list.\n","\n","As we want to combine sentiment with the company name later, we will limit the output to one name per headline.\n","\n","In order to format the output as a Python list, we can make use of the `CommaSeparatedListOutputParser` class in Langchain."]},{"cell_type":"markdown","id":"60d62a05-8c14-4d02-b6ed-1d896f222724","metadata":{},"source":["### Instructions\n","\n","Create an output parser and a formatted prompt template to extract company names from multiple headlines.\n","- Import `CommaSeparatedListOutputParser` from `langchain.output_parsers`.\n","- Instantiate a new `CommaSeparatedListOutputParser` and assign to `output_parser`.\n","- To retrieve the parsing instructions from the output parser, we can use its `.get_format_instructions()` method. Assign this to `format_instructions`.\n","- Let's instantiate a new `PromptTemplate`. This time we won't use its `.from_template()` method. When calling `PromptTemplate()` with the output parser, we need to pass three arguments:\n","    - `template`: here we can use the following string; \n","```\n","\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\"\n","```\n","\n","- `input_variables`: This is a list of strings containing the input variables that are required. In our case, this is only `\"headlines\"`.\n","- `partial_variables`: Here we pass along a dictionary with the key being `\"format_instructions\"` and the value being the `format_instructions` variable we created earlier.\n","- Format the prompt template using the entire `headlines` list."]},{"cell_type":"markdown","id":"69682dd4-6bf4-4a4e-a85f-0a6757112956","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","We can create a new prompt template using `PromptTemplate(template= , input_variables= , partial_variables= )`\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":17,"id":"6cac36e4-9d98-414e-8204-848c299a3457","metadata":{},"outputs":[],"source":["# Import the CommaSeparatedListOutputParser class.\n","from langchain.output_parsers import CommaSeparatedListOutputParser\n","\n","# Instantiate the output parser.\n","output_parser = CommaSeparatedListOutputParser()\n","\n","# Get the format instructions from the output parser.\n","format_instructions = output_parser.get_format_instructions()\n","\n","# Instantiate a new prompt template with the format instructions.\n","company_name_template = PromptTemplate(\n","    template=\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\",\n","    input_variables=[\"headlines\"],\n","    partial_variables={\"format_instructions\": format_instructions}\n",")\n","\n","# Format the prompt using all headlines.\n","formatted_company_name_template = company_name_template.format(headlines=headlines)"]},{"cell_type":"markdown","id":"54576b7b-2048-49f6-939c-ced2c8a834d9","metadata":{},"source":["Now that we have a template with format instructions ready, let's send it to a GPT-model and look at the output. We want to run these kinds of tasks with the temperature parameter of the large language model set to zero, as this maximizes precision. \n","\n","We tend to distinguish tasks that either require precision or creativity. When we are looking for correctness in the answer (e.g. when generating code) we aim for high precision (by lowering temperature) whereas when generating ideas or content, we might prefer more creativity (by increasing temperature). A simplified explanation of the *temperature* of a large language model is its randomness. When temperature is set to 0, we will get the exact same output, given the same inputs."]},{"cell_type":"markdown","id":"e00a6e04-c726-4dc1-a240-9f0b3291de28","metadata":{},"source":["### Instructions\n","\n","Create a new Langchain model, send over the template and inspect the parsed output.\n","- Instantiate a new `OpenAI()` model. Set the temperature to 0. Assign to `model`.\n","- Run `model()` on the formatted template. Assign to `_output`. The underscore preceding our variable name indicates that this is just a temporary variable, that will likely be overwritten many times.\n","- Use the `.parse()` method of the output parser on the output of the model. Assign to `company_names`.\n","- Print the data type of `company_names`.\n","- Print the company names."]},{"cell_type":"markdown","id":"20ea561c-9b4f-4e6c-a630-eef71d2fc43d","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","- The temperature of the model can be set to 0 by using `OpenAI(temperature= )`.\n","- We can get the data type of a variable by using `type(variable)`.\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":18,"id":"f1dde4f8-ccb5-4bf0-a7d6-35f1a1f6e66a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/workspaces/datacamp/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"name":"stdout","output_type":"stream","text":["Data type: <class 'list'>\n","\n","['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology']\n"]}],"source":["# Instantiate a Langchain OpenAI Model object.\n","model = OpenAI(temperature=0)\n","\n","# Run the model on the input.\n","_output = model(formatted_company_name_template)\n","\n","# Parse the output.\n","company_names = output_parser.parse(_output)\n","\n","# Print the data type the parsed output.\n","print(f\"Data type: {type(company_names)}\\n\")\n","\n","# Print the output.\n","print(company_names)"]},{"cell_type":"markdown","id":"f8ab6d2c-87d1-4966-bac0-99f3ba39d195","metadata":{},"source":["## Task 5: Working with Agents and Tools"]},{"cell_type":"markdown","id":"fa5daf04-5793-4fdc-a6d8-268430d7ab17","metadata":{},"source":["Leveraging the agents and tools in LangChain is where the framework's value really starts to shine! But before we dive deeper into this concept, we need to understand MRKL prompts."]},{"cell_type":"markdown","id":"c8f4e729-a8e9-4d28-bc3f-752cb3efc620","metadata":{},"source":["### What are MRKL Prompts?\n","\n","MRKL stands for Modular Reasoning, Knowledge and Language prompts. It is a system composed of a set of modules, often accompanied by an agent that decides how to route prompts to the appropriate module (or tools).\n","\n","These kinds of prompts follow a specific format, which we can force the GPT-model to adhere to by using the system message. It will loop through this format (steps 1-5 below) using recursive requests to the GPT-model until we get our final answer. A commonly used format is the following:\n","1. Question: the user question (in the first iteration) or follow-up question composed by the GPT-models (in later iterations)\n","2. Thought: think about what to do as a next step\n","3. Action: pick a tool from the list of tool names we have provided\n","4. Action Input: the input for the chosen tool\n","5. Observation: the output of the tool"]},{"cell_type":"markdown","id":"709a8d80-fb26-4f83-9cf2-19e6cbb00557","metadata":{},"source":["### What are Tools and Agents?\n","\n","We can access (external) tools using the output of the GPT-model. Large language models output only text. In order to call a function (to access a tool) based on the text output of a large language model, we can use agents. They can parse the text output, pick the correct tool and define its input.\n","\n","The langchain framework has a wide variety of built-in tools, along with the ability to define additional custom tools. A very common use case for tools is accessing document stores or vector databases to ingest information from our own documents. This will be explored more in-depth in future modules.\n","\n","For now, to have a gentle introduction to tools, we have decided on one that does not require external set up (no API token that needs to be created or external database that needs to be set up). \n","\n","In this example, we will make use of the `PythonREPLTool`. This allows the GPT-model to run the Python code that it generates, and can be useful for carrying out an abundance of tasks.\n","\n","Note: as we introduce recursive prompts using agents, it is best practice to always define a maximum number of output tokens. This ensures our costs will not skyrocket if a prompt loop takes too long."]},{"cell_type":"markdown","id":"7234a5ec-0f44-4ca6-9d2e-0a983386b7e7","metadata":{},"source":["### Instructions\n","\n","Before we continue with our financial analysis, let's create a quick example of how code can be ran using a Python agent. In this case, we will ask it to make a calculation (something that most large language models are not trained to do out-of-the-box).\n","- Import the `create_python_agent` function from `langchain.agents.agent_toolkits`.\n","- Import the `PythonREPLTool` class from `langchain.tools.python.tool`.\n","- Create a Python agent by calling the `create_python_agent()` function. Assign to `agent_executor`. This function takes three arguments:\n","    - `llm`: here we can create a new `OpenAI()` model. Let's set the `temperature` to 0 and `max_tokens` to 1000.\n","    - `tool`: here we instantiate a new `PythonREPLTool()`.\n","    - `verbose`: set this to True so that can we see the prompt loop.\n","- Run the agent using its `.run()` method. As an example, you can ask it: `\"What is the square root of 250? Round the answer down to 4 decimals.\"`"]},{"cell_type":"code","execution_count":19,"id":"9016d465-16b8-48d8-af78-3384a113eaa3","metadata":{},"outputs":[],"source":["# # Import the necessary classes from langchain.\n","# from langchain.agents.agent_toolkits import create_python_agent\n","# from langchain.tools.python.tool import PythonREPLTool\n","\n","# # Instantiate a Python agent, with the PythonREPLTool.\n","# agent_executor = create_python_agent(\n","#     llm=OpenAI(temperature=0, max_tokens=1000),\n","#     tool=PythonREPLTool(),\n","#     verbose=True\n","# )\n","\n","# # Ask the agent for the solution of a mathematical equation.\n","# agent_executor.run(\"What is the square root of 250? Round the answer down to 4 decimals.\")"]},{"cell_type":"code","execution_count":20,"id":"62f523de","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain_experimental in /workspaces/datacamp/.venv/lib/python3.12/site-packages (0.0.57)\n","Requirement already satisfied: langchain<0.2.0,>=0.1.15 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain_experimental) (0.1.16)\n","Requirement already satisfied: langchain-core<0.2.0,>=0.1.41 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain_experimental) (0.1.46)\n","Requirement already satisfied: PyYAML>=5.3 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (2.0.29)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.0.34)\n","Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.0.1)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (0.1.51)\n","Requirement already satisfied: numpy<2,>=1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (2.7.1)\n","Requirement already satisfied: requests<3,>=2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.15->langchain_experimental) (8.2.3)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.41->langchain_experimental) (23.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.9.4)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain_experimental) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.15->langchain_experimental) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.10.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain_experimental) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain_experimental) (2.18.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain_experimental) (4.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain_experimental) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.15->langchain_experimental) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /workspaces/datacamp/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain_experimental) (1.0.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install langchain_experimental"]},{"cell_type":"code","execution_count":21,"id":"d3ef1e11","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Python REPL can execute arbitrary code. Use with caution.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[32;1m\u001b[1;3m I can use the math module to calculate the square root.\n","Action: Python_REPL\n","Action Input: import math\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m Now that the math module is imported, I can use the sqrt function.\n","Action: Python_REPL\n","Action Input: math.sqrt(250)\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m The result is a float, so I can use the round function to round it down to 4 decimals.\n","Action: Python_REPL\n","Action Input: round(math.sqrt(250), 4)\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n","Final Answer: 15.8114\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'15.8114'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Import the necessary classes from langchain.\n","from langchain_experimental.agents.agent_toolkits import create_python_agent\n","from langchain_experimental.tools.python.tool import PythonREPLTool\n","\n","# Instantiate a Python agent, with the PythonREPLTool.\n","agent_executor = create_python_agent(\n","    llm=OpenAI(temperature=0, max_tokens=1000),\n","    tool=PythonREPLTool(),\n","    verbose=True\n",")\n","\n","# Ask the agent for the solution of a mathematical equation.\n","agent_executor.run(\"What is the square root of 250? Round the answer down to 4 decimals.\")"]},{"cell_type":"markdown","id":"867eb98e-bcc4-4278-a562-94e4ff9072b6","metadata":{},"source":["Investigate the output above. As we haven't assigned any other tool, the choice of tools for the model was quite limited. Hence under Action, it should list the `Python_REPL` tool.\n","The Action Input will show the actual code that was generated by the GPT-model and executed by the Agent.\n","\n","Now let's try to use the same agent to help us in our financial news analysis.\n","\n","We want to structure our prompt in a clear way, explaining a step by step process. For example:\n","- First, *Analyze the sentiment...*\n","- Second, *Load this data into a pandas dataframe.*\n","- Third, *Save this dataframe to a CSV under the name financial_analysis.csv*\n","- ...\n","\n","Lastly, we pass along the headlines (input data) itself."]},{"cell_type":"markdown","id":"044d23e5-930f-4a11-b3ff-fb42e61222cd","metadata":{},"source":["### Instructions\n","\n","Ask the agent to extract the company name and sentiment from the headlines and save its output in a `.csv` file called `financial_analysis.csv`.\n","- Run the agent on the following prompt:\n","    \n","    ``` \n","    f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \n","    Load this data into a pandas dataframe. \n","    The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n","    The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n","    If a csv file already exists with the same name, it should be overwritten.\n","\n","    The headlines are the following:\n","    {headlines}\"\"\"\n","    ```"]},{"cell_type":"code","execution_count":22,"id":"d6b142a8-d387-4738-90de-c4d7f7d74fc3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m I need to import the necessary libraries and create a dataframe to store the extracted data.\n","Action: Python_REPL\n","Action Input: import pandas as pd\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to create a list of the headlines.\n","Action: Python_REPL\n","Action Input: headlines = [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to create a list of the company names and financial sentiments.\n","Action: Python_REPL\n","Action Input: company_names = ['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology']\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to create a list of the financial sentiments.\n","Action: Python_REPL\n","Action Input: financial_sentiments = ['positive', 'negative', 'positive', 'positive', 'positive', 'positive']\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to create a dictionary to store the extracted data.\n","Action: Python_REPL\n","Action Input: data = {'Company Name': company_names, 'Financial Sentiment': financial_sentiments, 'Headline': headlines}\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to convert the dictionary into a dataframe.\n","Action: Python_REPL\n","Action Input: df = pd.DataFrame(data)\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to save the dataframe as a csv file.\n","Action: Python_REPL\n","Action Input: df.to_csv('financial_analysis.csv', index=False)\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n","Final Answer: The dataframe containing the extracted data has been saved as financial_analysis.csv in the current working directory.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'The dataframe containing the extracted data has been saved as financial_analysis.csv in the current working directory.'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Run the agent\n","agent_executor.run(f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is   positive, neutral or negative. \n","   Load this data into a pandas dataframe. \n","   The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n","   The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n","   If a csv file already exists with the same name, it should be overwritten.\n","\n","   The headlines are the following:\n","   {headlines}\n","   \"\"\")"]},{"cell_type":"markdown","id":"f4865a0e-2caf-4242-802f-1553ba1d3b5d","metadata":{},"source":["Observe the output above. Do you see anything that could be improved? We will come back to this later in this notebook.\n","\n","For now, let's quickly load our `.csv` file in a dataframe to analyze."]},{"cell_type":"markdown","id":"86270b08-e124-43bb-8834-210bdb6c0a43","metadata":{},"source":["### Instructions\n","\n","Load the data in a dataframe for evaluation.\n","- Import `pandas` under its usual alias: `pd`.\n","- Load the `financial_analysis.csv` file into a dataframe. Assign to `df`.\n","- Print the dataframe. As our dataframe only contains six rows, we can just print the entire dataframe."]},{"cell_type":"markdown","id":"de02653d-dda5-432a-ba2b-16f5faf0686e","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","Use the `pd.read_csv(filename)` function to load the `.csv` file to dataframe.\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":23,"id":"e1c01e13-0d39-407d-80f6-f0ebe5f76827","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Company Name</th>\n","      <th>Financial Sentiment</th>\n","      <th>Headline</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Aktia Group</td>\n","      <td>positive</td>\n","      <td>Finnish Aktia Group 's operating profit rose t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Vaisala Oyj</td>\n","      <td>negative</td>\n","      <td>Finnish measuring equipment maker Vaisala Oyj ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Orion</td>\n","      <td>positive</td>\n","      <td>Finnish pharmaceuticals company Orion reports ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tiimari</td>\n","      <td>positive</td>\n","      <td>Tiimari , the Finnish retailer , reported to h...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metso Paper</td>\n","      <td>positive</td>\n","      <td>Finnish Metso Paper has been awarded a contrac...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Company Name Financial Sentiment  \\\n","0  Aktia Group            positive   \n","1  Vaisala Oyj            negative   \n","2        Orion            positive   \n","3      Tiimari            positive   \n","4  Metso Paper            positive   \n","\n","                                            Headline  \n","0  Finnish Aktia Group 's operating profit rose t...  \n","1  Finnish measuring equipment maker Vaisala Oyj ...  \n","2  Finnish pharmaceuticals company Orion reports ...  \n","3  Tiimari , the Finnish retailer , reported to h...  \n","4  Finnish Metso Paper has been awarded a contrac...  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Make the necessary import.\n","import pandas as pd\n","\n","# Load the CSV file into a dataframe.\n","df = pd.read_csv(\"financial_analysis.csv\")\n","\n","# Print the dataframe.\n","df.head()"]},{"cell_type":"markdown","id":"d37d368b-b177-41f9-abe8-dacf99486401","metadata":{},"source":["When analyzing the output above (looking at the company names and sentiment), you will probably notice some room for improvement. \n","\n","Company names and sentiment may not be extracted in a very powerful way. The reason for this is that without further instructions, the GPT-model will use the PythonREPLTool (Python code) to complete its task. Looking back at the output from our last call to the Python agent, we may find that it created rule sets on how to extract the company name or determine the sentiment. These hard-coded rules negate the power of large language models! We will improve on this in Task 7.\n","\n","Another problem that might arise is that the *sentiment* of a sentence can differ from *financial sentiment*. For example, an aggressive headline complaining about a large corporation making too much profit might result in negative sentiment, while from a financial analysis point of view the sentiment is positive. To steer the GPT-model to our desired outcome, we will now introduce few shot learning.\n","\n","For example, *Company X was awarded a new contract* might be categorized as a neutral sentence. The sentence itself is simply an objective statement or observation. Nothing is mentioned about whether we like or dislike that particular company because of this. From a financial perspective however, this is considered as something positive. To steer the GPT-model to our desired outcome, we will now introduce few shot learning."]},{"cell_type":"markdown","id":"31bb73ca-089b-4bdf-ba9f-e2efbe3174f0","metadata":{},"source":["## Task 6: Adding Few Shot Learning"]},{"cell_type":"markdown","id":"cbe98ba4-9d30-40e7-8a80-d8b780a48105","metadata":{},"source":["Few shot learning basically comes down to adding some examples into our prompt, in this case, what we consider to be positive or negative headlines. A shot refers to an example given to the model in the input prompt (or sometimes the system message).\n","\n","We distinguish three categories of contextual learning:\n","- Few shot leaning (multiple examples)\n","- Single shot learning (one example)\n","- Zero shot leaning (no examples)\n","\n","Few shot learning might take more effort in terms of prompt building, but it will generally yield better results, as the model has a better understanding of our desired outcome.\n","\n","Let's look at an example of financial sentiment analysis without few shot learning first."]},{"cell_type":"markdown","id":"59658d1d-3b7c-4e7c-8521-c295982c3de7","metadata":{},"source":["### Instructions\n","\n","Create a prompt template with output parsing to determine the financial sentiment of all headlines.\n","- Create a new `PromptTemplate` called `sentiment_template`. Remember the three arguments `template`, `input_variables` and `partial_variables`. Assign to `sentiment_template`.\n","    - We can reuse the `format_instructions` variable that we have loaded into memory before.\n","    - As a template, use: \n","```\n","\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\"\n","```\n","\n","\n","- Format the template on all headlines. Assign to `formatted_sentiment_template`.\n","- Run the formatted template through our `model` and assign the result to our temporary variable `_output`.\n","- Parse the output using the output parser. Assign the result to `sentiments`.\n","- Print the sentiments."]},{"cell_type":"code","execution_count":24,"id":"30dc1956-488a-4c93-a887-a5ea803f30a4","metadata":{},"outputs":[{"data":{"text/plain":["['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Create a new prompt template with output parsing.\n","sentiment_template = PromptTemplate(\n","    template=\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n","    input_variables=[\"headlines\"],\n","    partial_variables={\"format_instructions\": format_instructions}\n",")\n","\n","# Format the prompt template.\n","formatted_sentiment_template = sentiment_template.format(headlines=headlines)\n","\n","# Run the model on the formatted prompt template.\n","_output = model(formatted_sentiment_template)\n","\n","# Parse the output.\n","sentiments = output_parser.parse(_output)\n","\n","# Print the list of sentiments.\n","sentiments"]},{"cell_type":"markdown","id":"843f4c4d-8185-4ebe-991b-1d179cc5e15a","metadata":{},"source":["It is hard to evaluate the sentiments without seeing the associated headline. To make our lives easier, let's write a quick function to easily visualize and interpret the result."]},{"cell_type":"markdown","id":"da3d6834-6c1e-4542-80f3-dc1b385f6477","metadata":{},"source":["### Instructions\n","\n","Visualize and interpret the results of the sentiment analysis.\n","- Write a function called `visualize_sentiments` to visualize both the sentiment and associated headline, for all headlines. \n","    - The input for this function should be two lists: one containing all headlines and one containing all sentiments.\n","    - As a best practice, start with using an `assert` that ensures that both lists are of equal length.\n","    - There are many ways to create this: simply printing with f-strings, making a dictionary or Dataframe, get creative!\n","- Call the `visualize_sentiments` function using `headlines` and `sentiments` as input."]},{"cell_type":"markdown","id":"5bf24583-5de7-45fb-849b-16db6d86b724","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","- We can assert that both input lists are of equal length by using `assert len(list1) == len(list2)`.\n","- A very simplistic way of visualizing the sentiments per headline is using f-strings, such as `f\"{sentiments[i]}: {headlines[i]}\"` in a loop. \n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":25,"id":"4e7ca1a7-4249-4826-ac57-5093ee3de9d1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["POSITIVE: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\n","NEGATIVE: Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\n","POSITIVE: Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\n","POSITIVE: Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\n","POSITIVE: Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\n","POSITIVE: Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"]}],"source":["# Define a new function with two inputs,\n","def visualize_sentiments(headlines, sentiments):\n","    # Assert that both inputs are of equal length\n","    assert len(headlines) == len(sentiments)\n","\n","    # Visualize the sentiments and their respective headlines\n","    for i, _ in enumerate(headlines):\n","        print(f\"{sentiments[i].upper()}: {headlines[i]}\")\n","\n","# Call the function\n","visualize_sentiments(headlines, sentiments)"]},{"cell_type":"markdown","id":"3bc7af8c-461c-42d2-ae37-2da14438c5c6","metadata":{},"source":["Now we might see that the financial sentiment is not always correctly assigned, such as a contract being awarded not being recognized as a financially positive headline.\n","To improve the performance, we will add some examples. Few shot learning can be done by either giving some observations (headlines in this case) accompanied by their ground truth (label) *or* by giving an abstract description of what is seen as positive, negative or neutral.\n","\n","In this case, we will opt for the later. Here is a prompt you can use for few shot learning:\n","\n","```\n","\"\"\"\n","If a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\n","If the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\n","If nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n","\"\"\"\n","```"]},{"cell_type":"markdown","id":"3142596a-b723-4d4f-9d2d-2066531aeea6","metadata":{},"source":["### Instructions\n","\n","Create and run a prompt template using few shot learning.\n","- Store the prompt above in a variable called `sentiment_examples`.\n","- Create a `PromptTemplate` called `sentiment_template` like we did two cells above.\n","    - In our template, we will add a new input variable called `few_shot_examples`. This can be placed in between the two sentences.\n","    - Don't forget to add our new input variables to the list of `input_variables`.\n","    - Reuse the same `format_instructions` as before.\n","- Format the `sentiment_template`. Remember that you will need to pass both `headlines` and `sentiment_examples`.\n","- Run the formatted template through our `model` and assign the result to our temporary variable `_output`.\n","- Parse the output using the output parser. Assign the result to `sentiments`.\n","- Visualize and interpret the results using your newly created `visualize_sentiments` function."]},{"cell_type":"markdown","id":"7364ebe9-17a1-4888-844c-89efeb3b1c9b","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","The `template` we should use could look like this: \n","\n","```\n","\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to [`Positive`, `Negative`, `Neutral`]: {headlines}.\\n{format_instructions}\"\n","```\n","\n","When formatting the template, we can pass along `sentiment_examples` to the `few_shot_examples` input variable.\n","    \n","</p>\n","</details>"]},{"cell_type":"code","execution_count":26,"id":"78e963c2-d4a5-409b-b4b7-7a1d30a13346","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["POSITIVE: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\n","NEGATIVE: Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\n","POSITIVE: Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\n","POSITIVE: Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\n","POSITIVE: Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\n","POSITIVE: Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"]}],"source":["# Store the few shot examples in a variable.\n","sentiment_examples = \"\"\"\n","    If a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\n","    If the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\n","    If nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n","\"\"\"\n","\n","# Instantiate a new prompt template with the format instructions.\n","sentiment_template = PromptTemplate(\n","    template=\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n","    input_variables=[\"headlines\", \"few_shot_examples\"],\n","    partial_variables={\"format_instructions\": format_instructions}\n",")\n","\n","# Format the template.\n","formatted_sentiment_template = sentiment_template.format(headlines=headlines, few_shot_examples=sentiment_examples)\n","\n","# Run the model on the formatted template.\n","_output = model(formatted_sentiment_template)\n","\n","# Parse the model output.\n","sentiments = output_parser.parse(_output)\n","\n","# Visualize the result.\n","visualize_sentiments(headlines, sentiments)"]},{"cell_type":"markdown","id":"300e7f24-e934-4c49-a710-c67cb3413693","metadata":{},"source":["## Task 7: Combining Tools and Output Parsing"]},{"cell_type":"markdown","id":"4e447e81-3b31-4e74-a567-53623cc863ce","metadata":{},"source":["As you may have noticed in Task 5, using tools is not a guaranteed success. We can improve the performance by clearly determining which tasks can be completed by the Python tool and which we use the GPT-model itself for.\n","To maximize the powerful capabilities of the GPT-model, we prefer its use over hard-coded rule sets when it comes to company name extraction or financial sentiment analysis.\n","However, other (cumbersome) tasks that do not require the ability to handle ambiguity, are often best left to the Python tool.\n","\n","Let's ask the model to use the existing lists that we got from our templates (`company_names` and `sentiments`), but use the Python tool to neatly place them in a Pandas dataframe and write them locally to a `.csv` file.\n","\n","Use the following prompt:\n","\n","```\n","f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n","                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n","                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n","                   If a csv file already exists with the same name, it should be overwritten.\n","                   \"\"\"\n","```\n","\n","In the prompt above, we pass along lists that were generated by the GPT-model before (when it did not have access to the Python tool). Now we only want to give instructions on tasks that should be carried out using Python code, such as the creation of the dataframe, saving (and overwriting) it, ...\n","\n","Keep in mind that we can use this same way of working for much more complex tasks, that might encompass extensive coding requirements."]},{"cell_type":"markdown","id":"d690b3d5-2602-4c3b-990f-85990d4e301d","metadata":{},"source":["### Instructions\n","\n","- Run the `agent_executor` on the prompt above."]},{"cell_type":"code","execution_count":27,"id":"188e0ab4-1515-49a2-a8db-09582ec5be21","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m I need to import the pandas library to create a dataframe.\n","Action: Python_REPL\n","Action Input: import pandas as pd\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to create the lists for the columns and data.\n","Action: Python_REPL\n","Action Input: company_name = ['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology']\n","sentiment = ['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']\n","headline = [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to create a dataframe using the lists.\n","Action: Python_REPL\n","Action Input: df = pd.DataFrame({'company_name': company_name, 'sentiment': sentiment, 'headline': headline})\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to save the dataframe as a csv file.\n","Action: Python_REPL\n","Action Input: df.to_csv('financial_analysis_with_parsing.csv', index=False)\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n","Final Answer: The dataframe has been successfully created and saved as a csv file in the current working directory under the name financial_analysis_with_parsing.csv.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'The dataframe has been successfully created and saved as a csv file in the current working directory under the name financial_analysis_with_parsing.csv.'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Run the agent to create a file with the headlines, company names and sentiments.\n","agent_executor.run(f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n","To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n","The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n","If a csv file already exists with the same name, it should be overwritten.\n","\"\"\")"]},{"cell_type":"markdown","id":"477b7d8a-2e4e-4f74-8dc1-b538fcd09f23","metadata":{},"source":["If we look at our working directory, we will see a new file pop up, called `financial_analysis_with_parsing.csv`.\n","\n","Let's analyze it and compare against the output from Task 5."]},{"cell_type":"markdown","id":"9ed9c0b7-f961-493e-8a38-7143050448f8","metadata":{},"source":["### Instructions\n","\n","Load and display the new file.\n","- Load `financial_analysis_with_parsing.csv` into a dataframe called `df`.\n","- Print the dataframe."]},{"cell_type":"code","execution_count":28,"id":"142e344b-16c6-46fa-996f-3c1da9b52956","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>company_name</th>\n","      <th>sentiment</th>\n","      <th>headline</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Aktia Group</td>\n","      <td>Positive</td>\n","      <td>Finnish Aktia Group 's operating profit rose t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Vaisala Oyj</td>\n","      <td>Negative</td>\n","      <td>Finnish measuring equipment maker Vaisala Oyj ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Orion</td>\n","      <td>Positive</td>\n","      <td>Finnish pharmaceuticals company Orion reports ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tiimari</td>\n","      <td>Positive</td>\n","      <td>Tiimari , the Finnish retailer , reported to h...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Metso Paper</td>\n","      <td>Positive</td>\n","      <td>Finnish Metso Paper has been awarded a contrac...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Outokumpu Technology</td>\n","      <td>Positive</td>\n","      <td>Finnish Outokumpu Technology has been awarded ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           company_name sentiment  \\\n","0           Aktia Group  Positive   \n","1           Vaisala Oyj  Negative   \n","2                 Orion  Positive   \n","3               Tiimari  Positive   \n","4           Metso Paper  Positive   \n","5  Outokumpu Technology  Positive   \n","\n","                                            headline  \n","0  Finnish Aktia Group 's operating profit rose t...  \n","1  Finnish measuring equipment maker Vaisala Oyj ...  \n","2  Finnish pharmaceuticals company Orion reports ...  \n","3  Tiimari , the Finnish retailer , reported to h...  \n","4  Finnish Metso Paper has been awarded a contrac...  \n","5  Finnish Outokumpu Technology has been awarded ...  "]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Load the CSV file into a dataframe.\n","df = pd.read_csv(\"financial_analysis_with_parsing.csv\")\n","\n","# Print the dataframe.\n","df"]},{"cell_type":"markdown","id":"50ca52ca-41f3-4aea-bd0a-4862a9465a7a","metadata":{},"source":["## Task 8: Using the OpenAI Moderation API"]},{"cell_type":"markdown","id":"27cd50c5-43a2-4082-8dde-d92c183d38cd","metadata":{},"source":["The OpenAI API platform also sports a Moderation API, in addition to their model and embeddings APIs. The Moderation API can check whether the prompt contains explicit content and can flag various categories like hate, violence, sexually explicit content and so on. When we are building an application targeting large user bases, it becomes crucial to leverage the Moderation API and filter our input prompts to avoid the complications associated with unethical LLM usage.\n","\n","To test the Moderation API, we have a small sample of five comments picked from the `r/WallStreetBets` subreddit, stored in the `reddit_comments.txt` file.\n","\n","Let's start by reading the text file."]},{"cell_type":"markdown","id":"b05cfef2-ba53-4372-a6f3-c998f1d25164","metadata":{},"source":["### Content warning\n","\n","In order to trigger the moderation API, the comments were specifically chosen to be offensive. If you are sensitive to awful content, you may wish to avoid printing and reading the text.\n","\n","Naturally, neither the project instructor nor DataCamp agrees with the ideas expressed within this text file."]},{"cell_type":"markdown","id":"4e66ebca-010f-4189-b2fd-3a33ec0b378d","metadata":{},"source":["### Instructions\n","\n","Read the text file and store its lines in a variable called `comments`.\n","- Open `reddit_comments.txt` as read.\n","- Use the `.readlines()` method to store its contents in a list called `comments`.\n","- Optionally print the comments."]},{"cell_type":"markdown","id":"7772dd1f-97c0-4713-8836-e06c859b905f","metadata":{},"source":["<details>\n","<summary>Code hints</summary>\n","<p>\n","\n","Here we can use the same `with open(filename, \"r\") as file:` structure as in Task 1.\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":29,"id":"a5a029ff-5387-49f7-8a77-e3cdd40e7282","metadata":{"executionCancelledAt":null,"executionTime":175,"lastExecutedAt":1696556993785,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the lines of the text file.\n\n\n# Optionally print the comments.\n# comments"},"outputs":[{"data":{"text/plain":["[\"It's the poors fault for thinking they had a chance in a negative sum gambling casino run by people richer than you who hired Asian quants that are smarter than you.\\n\",\n"," \"Canada is basically a global real estate investment scheme. It's not even a country, it's a showroom.\\n\",\n"," 'Lol China not going to make a dent in the global scale. Wake me up when Americas housing market is about to implode thats when Im pulling out all my investments. Because the world is going to burn.\\n',\n"," 'I would normally have the knee-jerk reaction to seethe at this post but I remind myself that if I had a lot of money I would probably be the snobbiest and stingiest rich person ever. I wouldnt even help anyone even if they begged me to financially free them from their Wendys dumpster obligations\\n',\n"," \"I know China will be fine because Peter Zeihan keeps saying China is imploding. If you want to know what the US State Department desperately wants you to believe, just keep up to date with whatever Peter Zeihan is saying. The dude somehow made a career about being wrong about everything all the time and always blindsided by new developments. 3 months ago he's doing vblogs about how China is completely cut off from semiconductors and the immensely complicated tech necessary to catch up - and then last week it's revealed China has beaten USA to producing 7nm chips domestically. Literally just 3 months ago Zeihan and everyone educated by Western news sources thought China would be stuck at 28nm for years to come. If the rumours circulating of China developing SSMB EUV are true then it's truly game over, China's won\"]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Load the lines of the text file.\n","with open('reddit_comments.txt', 'r') as data:\n","    comments = data.readlines()\n","\n","# Optionally print the comments.\n","comments"]},{"cell_type":"markdown","id":"e3b3e694-2176-4d46-91a2-7c17ef31b980","metadata":{},"source":["### Instructions\n","\n","Analyze a comment using the Moderation API.\n","- Pick a comment from the dataset (using and index between 0 - 4) and store this in a variable called `comment`.\n","- Use the API by calling `openai.Moderation.create()`. For the `input` argument, we will pass along the `comment`. Assign to `moderation_output`.\n","- Print the comment and moderation output."]},{"cell_type":"code","execution_count":30,"id":"306b2862-bcdb-4e67-add4-c776ddc14c5f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["It's the poors fault for thinking they had a chance in a negative sum gambling casino run by people richer than you who hired Asian quants that are smarter than you.\n","\n"]},{"data":{"text/plain":["ModerationCreateResponse(id='modr-9IKAwm60U9Eu3sMs7zCT0rrZ3lZuc', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=True, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=0.9698249697685242, harassment_threatening=5.6962966482387856e-05, hate=0.2250063419342041, hate_threatening=1.5335608338773454e-07, self_harm=9.122244648551714e-08, self_harm_instructions=1.5766876515499462e-07, self_harm_intent=2.0730141159219784e-08, sexual=8.78242735780077e-06, sexual_minors=2.3513287317200593e-07, violence=0.00021562023903243244, violence_graphic=4.008067833183304e-07, self-harm=9.122244648551714e-08, sexual/minors=2.3513287317200593e-07, hate/threatening=1.5335608338773454e-07, violence/graphic=4.008067833183304e-07, self-harm/intent=2.0730141159219784e-08, self-harm/instructions=1.5766876515499462e-07, harassment/threatening=5.6962966482387856e-05), flagged=True)])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Import the openai package.\n","from openai import OpenAI\n","client = OpenAI()\n","\n","# Pick a comment.\n","comment = comments[0]\n","\n","# Send the comment to the Moderation API.\n","moderation_output = client.moderations.create(input=comment)\n","\n","# Optionally print the comment.\n","print(comment)\n","\n","# Print the output.\n","moderation_output\n"]},{"cell_type":"markdown","id":"1ec05e3a-144a-4abd-8a1c-02b72e2cb41f","metadata":{},"source":["We can analyze the output above to determine whether the comment has been deemed explicit or not. The `\"flagged\"` boolean will show us if any (at least one) category has been flagged, and underneath we can see which categories have been flagged."]},{"cell_type":"markdown","id":"b81d3a0b-b9ac-4def-b19a-b501a42d9ff2","metadata":{},"source":["## Summary"]},{"cell_type":"markdown","id":"6c9ba593-30fa-43b5-9b18-2bd6c7e4087e","metadata":{},"source":["Congratulations on completing this module! You should be able to get started with basic LangChain projects yourself now. \n","\n","You've learned:\n","- Important prompt engineering tricks and optimizations\n","- Setting up prompt templates\n","- Using LLMChains\n","- Using LangChain output parsing to generate Python objects to be used downstream\n","- Using LangChain Agents and Tools to add additional functionalities to generative AI projects\n","- Leveraging the Moderation API to act as a filter of user input\n","\n","We wish you the best of luck in the following modules!"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}
